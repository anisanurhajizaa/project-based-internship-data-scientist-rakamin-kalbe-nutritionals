# -*- coding: utf-8 -*-
"""Machine Learning of Time Series Regression & Cluster Segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bTT7V9GQUio4MKbsKSCB7uEar_J4gq3w

**PREDICTIVE MODELING OF TIME SERIES REGRESSION AND CLUSTER SEGMENTATION IN MACHINE LEARNING**

Author: Anisa Nurhajiza

**LIBRARY**

---
"""

pip install pmdarima

# Library for data processing
import statsmodels.api as sm
import pandas as pd
import numpy as np

# Library for data visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Library for time series ARIMA modeling
from statsmodels.tsa.arima.model import ARIMA
from pmdarima.arima import auto_arima
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Library untuk Clustering
from sklearn import preprocessing
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

"""**READ DATASET**

---


"""

# Load dataset
customer = pd.read_csv('Case Study - Customer.csv',delimiter=';')
product = pd.read_csv('Case Study - Product.csv', delimiter=';')
store = pd.read_csv('Case Study - Store.csv', delimiter=';')
transaction = pd.read_csv('Case Study - Transaction.csv', delimiter=';')

"""**DATA CLEANING**

---




"""

# Data Profiling for the customer table
customer

customer.rename(columns={'Income,': 'Income'}, inplace=True)

customer.info()

customer.describe()

# Data Cleaning for the customer tabel
# Handling missing values in the Marital Status column using mode imputation

mode_value = customer['Marital Status'].mode()[0]
customer['Marital Status']= customer['Marital Status'].fillna(mode_value)
customer.head()

customer.isna().sum()

customer['Income'] = customer['Income'].str.replace(',', '.').astype(float)
customer = customer.astype({'Age': int,
                            'Gender': bool,
                            'Marital Status': 'category',
                            })

customer.info()

# Visualization of Age Distribution
plt.figure(figsize=(15,3))

plt.subplot(1,2,1)
sns.histplot(customer['Age'], color='Deeppink', kde=True)
plt.title("Distribution of Customer's Age", fontsize=16)
plt.xlabel('Age', fontsize = 14)
plt.ylabel('Frequency', fontsize = 14)

plt.show()

#  Visualization of Gender Distribution
plt.figure(figsize=(8,6))
sns.countplot(x='Gender', data = customer, hue='Gender', palette ='BuPu')
plt.title('Count Plot of Gender', fontsize=16)
plt.xlabel('Gender', fontsize = 14)
plt.ylabel('Count', fontsize = 14)
plt.xticks([0,1], ['Female', 'Male'], fontsize=12)
plt.show

# Visualization of Marital Status Distribution
plt.figure(figsize=(8,6))
sns.countplot(x='Marital Status', data = customer, hue='Marital Status', palette ='RdPu')
plt.title('Count Plot of Marital Status', fontsize=16)
plt.xlabel('Marital Status', fontsize = 14)
plt.ylabel('Count', fontsize = 14)

plt.show

# Data cleaning for the Product table
product

product.info()

product.describe()

# Data profiling for the Store table
store

# Data cleaning for the Store table
store['Latitude'] = store['Latitude'].str.replace(',', '.')
store['Longitude'] = store['Longitude'].str.replace(',', '.')

store = store.astype({'GroupStore':'category', 'Type':'category', 'Latitude':'float64', 'Longitude':'float64'})

store.info()

store.describe()

store.isna().sum()

store.info()

# Data cleaning for the Transaction table
transaction

transaction.info()

transaction.describe()

transaction.isna().sum()

# Data cleaning for the Transaction Table
transaction = transaction.astype({'Date':'datetime64[ns]'})

transaction.info()

"""**DATA MERGE**

---


"""

merged_data = pd.merge(customer, transaction, on='CustomerID')
merged_data = pd.merge(merged_data, product, on='ProductID')
merged_data = pd.merge(merged_data, store, on='StoreID')

merged_data.head()

df = pd.DataFrame(merged_data)

# Drop data
merged_data = merged_data.drop(['Price_y'], axis=1)
merged_data = merged_data.rename(columns={'Price_x': 'Price'})

merged_data

df = pd.DataFrame(merged_data)

# Calculating the total quantity of sales per store
store_quantity = df.groupby('StoreName')['Qty'].sum().reset_index()

# Creating a bar chart
pastel_colors = ['#FFD1DC', '#FFABAB', '#FFC3A0']
plt.figure(figsize=(10, 6))
plt.bar(store_quantity['StoreName'], store_quantity['Qty'], color=pastel_colors)
plt.xlabel('Store Name')
plt.ylabel('Total Sales Quantity')
plt.title('Total Sales Quantity per Store')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Calculating the total sales amount per product
product_amount = df.groupby('Product Name')['TotalAmount'].sum().reset_index()

# Bar Chart of the total sales amount per product
pastel_colors = ['#FFD1DC', '#C7EFCF', '#FFB5E8']
plt.figure(figsize=(10, 6))
plt.bar(product_amount['Product Name'], product_amount['TotalAmount'], color=pastel_colors)
plt.xlabel('Product Name')
plt.ylabel('Total Amount')
plt.title('Total Amounts per Product')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""**Machine Learning Regression (Time Series)**"""

# Performing a groupby based on the 'Date' column and aggregating the 'Qty' column using the SUM function
df = merged_data.groupby(['Date'])['Qty'].sum().reset_index()
print(df)

# Splitting into 90% train data and 10% test data
train_size = int(len(df) * 0.9)
df_train = df.iloc[:train_size]
df_test = df.iloc[train_size:]

# Split to train data and test data
df_train = df_train.set_index('Date')
df_test = df_test.set_index('Date')

y = df_train['Qty']

ARIMAmodel = ARIMA(y, order = (40, 2, 1))
ARIMAmodel = ARIMAmodel.fit()

y_pred = ARIMAmodel.get_forecast(len(df_test))

y_pred_df = y_pred.conf_int()
y_pred_df['predictions'] = ARIMAmodel.predict(start = y_pred_df.index[0], end = y_pred_df.index[-1])
y_pred_df.index = df_test.index
y_pred_out = y_pred_df['predictions']

y_pred_out

# Evaluate the model
# Mean Absolute Error (MAE)
mae = mean_absolute_error(df_test['Qty'], y_pred_out)
# Mean Squared Error (MSE)
mse = mean_squared_error(df_test['Qty'], y_pred_out)
# Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

print("MAE:", mae)
print("RMSE:", rmse)

plt.figure(figsize=(20,5))
plt.plot(df_train['Qty'], color='orchid')
plt.plot(df_test['Qty'], color='skyblue')
plt.plot(y_pred_out, color = 'sienna', label = 'ARIMA Predictions')
plt.legend()

"""**Machine Learning Clustering**"""

df_cluster = merged_data.groupby(['CustomerID']).agg({
    'TransactionID' : 'count',
    'Qty' : 'sum',
    'TotalAmount': 'sum'
}).reset_index()

df_cluster

data_cluster = df_cluster.drop(columns=['CustomerID'])
data_cluster_normalize = preprocessing.normalize(data_cluster)

data_cluster_normalize

K = range(2,8)
fits = []
score = []

for k in K:
    model = KMeans(n_clusters = k, random_state = 0, n_init='auto').fit(data_cluster_normalize)

    fits.append(model)

    score.append(silhouette_score(data_cluster_normalize, model.labels_, metric = 'euclidean'))

#choosing 4 cluster
sns.lineplot(x = K, y = score)

"""**Cluster Final Analysis**"""

df_cluster['cluster_label'] = fits[2].labels_

df_cluster.groupby(['cluster_label']).agg({
    'CustomerID' : 'count',
    'TransactionID' : 'mean',
    'Qty' : 'mean',
    'TotalAmount' : 'mean'
})

plt.figure(figsize=(11,6))
sns.set_style('white')
plt.scatter(x=df_cluster['Qty'], y=df_cluster['TotalAmount'], c=df_cluster['cluster_label'], cmap='spring')
scatter = plt.scatter(x=df_cluster['Qty'], y=df_cluster['TotalAmount'], c=df_cluster['cluster_label'], cmap='spring')
plt.xlabel('Total Qty', fontsize=15)
plt.ylabel('Total Amount', fontsize=15)
plt.title('Customer Segmentation Based on Total Quantity and Total Amount Spent', fontsize=18)


cluster_labels = df_cluster['cluster_label'].unique()
legend_labels = [f'Cluster {label}' for label in cluster_labels]

plt.legend(handles=scatter.legend_elements()[0], labels=legend_labels, title='Clusters')


plt.show